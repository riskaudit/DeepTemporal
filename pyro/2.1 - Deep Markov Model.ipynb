{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/joshuadimasaka/miniconda3/envs/opensendaibench/lib/python3.11/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: 'dlopen(/Users/joshuadimasaka/miniconda3/envs/opensendaibench/lib/python3.11/site-packages/torchvision/image.so, 0x0006): Symbol not found: __ZN3c1017RegisterOperatorsD1Ev\n",
      "  Referenced from: <CFED5F8E-EC3F-36FD-AAA3-2C6C7F8D3DD9> /Users/joshuadimasaka/miniconda3/envs/opensendaibench/lib/python3.11/site-packages/torchvision/image.so\n",
      "  Expected in:     <8E6D6BF5-9658-33B9-9D3C-DF587B2F99E7> /Users/joshuadimasaka/miniconda3/envs/opensendaibench/lib/python3.11/site-packages/torch/lib/libtorch_cpu.dylib'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?\n",
      "  warn(\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import logging\n",
    "import time\n",
    "from os.path import exists\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "import pyro\n",
    "import pyro.contrib.examples.polyphonic_data_loader as poly\n",
    "import pyro.distributions as dist\n",
    "import pyro.poutine as poutine\n",
    "from pyro.distributions import TransformedDistribution\n",
    "from pyro.distributions.transforms import affine_autoregressive\n",
    "from pyro.infer import (\n",
    "    SVI,\n",
    "    JitTrace_ELBO,\n",
    "    Trace_ELBO,\n",
    "    TraceEnum_ELBO,\n",
    "    TraceTMC_ELBO,\n",
    "    config_enumerate,\n",
    ")\n",
    "from pyro.optim import ClippedAdam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='mps', index=0)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.get_default_device()\n",
    "import os\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "os.environ['PYTORCH_ENABLE_MPS_FALLBACK'] = '1'\n",
    "torch.set_default_device('mps')\n",
    "torch.get_default_device()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Argument Parse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert pyro.__version__.startswith(\"1.9.1\")\n",
    "n = 10          # number of epochs\n",
    "lr = 0.0003     # learning rate\n",
    "b1 = 0.96       # beta1\n",
    "b2 = 0.999      # beta2\n",
    "cn = 10.0       # clip norm\n",
    "lrd = 0.99996   # lr decay\n",
    "wd = 2.0        # weight decay\n",
    "mbs = 20        # mini-batch size\n",
    "ae = 1000       # annealing epochs\n",
    "maf = 0.2       # minimum annealing epochs\n",
    "rdr = 0.1       # rnn dropout rate\n",
    "iafs = 0        # number of iafs\n",
    "id = 100        # iaf dim\n",
    "cf = 0          # checkpoint frequency\n",
    "\n",
    "lopt = ''       # load opt\n",
    "lmod = ''       # load model\n",
    "sopt = ''       # save opt\n",
    "smod = ''       # save model\n",
    "\n",
    "cuda = False    \n",
    "jit = False\n",
    "tmc = False\n",
    "tmcelbo = False\n",
    "tmc_num_samples = 10\n",
    "\n",
    "l = 'dmm_20240110.log'   # log\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup logging\n",
    "logging.basicConfig(\n",
    "    level=logging.DEBUG, format=\"%(message)s\", filename=l, filemode=\"w\"\n",
    ")\n",
    "console = logging.StreamHandler()\n",
    "console.setLevel(logging.INFO)\n",
    "logging.getLogger(\"\").addHandler(console)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = poly.load_data(poly.JSB_CHORALES)\n",
    "\n",
    "training_seq_lengths = data[\"train\"][\"sequence_lengths\"] \n",
    "# gives the size of each of the 229 sequences (called chorales); \n",
    "# e.g.. 1st has 129 as length (or the longest chorale)\n",
    "\n",
    "training_data_sequences = data[\"train\"][\"sequences\"]\n",
    "# gives the actual sequences in a form of matrix, where:\n",
    "# each row is a sequence or a chorale\n",
    "# each column is a step for each sequence (max of 129)\n",
    "# each entry for a given pair of row and column has length 88 (piano keys)\n",
    "\n",
    "test_seq_lengths = data[\"test\"][\"sequence_lengths\"]\n",
    "test_data_sequences = data[\"test\"][\"sequences\"]\n",
    "val_seq_lengths = data[\"valid\"][\"sequence_lengths\"]\n",
    "val_data_sequences = data[\"valid\"][\"sequences\"]\n",
    "\n",
    "N_train_data = len(training_seq_lengths)\n",
    "N_train_time_slices = float(torch.sum(training_seq_lengths))\n",
    "N_mini_batches = int(\n",
    "    N_train_data / mbs\n",
    "    + int(N_train_data % mbs > 0)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "N_train_data: 229     avg. training seq. length: 60.29    N_mini_batches: 12\n"
     ]
    }
   ],
   "source": [
    "logging.info(\n",
    "    \"N_train_data: %d     avg. training seq. length: %.2f    N_mini_batches: %d\"\n",
    "    % (N_train_data, training_seq_lengths.float().mean(), N_mini_batches)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# how often we do validation/test evaluation during training\n",
    "val_test_frequency = 50\n",
    "# the number of samples we use to do the evaluation\n",
    "n_eval_samples = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# how often we do validation/test evaluation during training\n",
    "val_test_frequency = 50\n",
    "# the number of samples we use to do the evaluation\n",
    "n_eval_samples = 1\n",
    "\n",
    "# package repeated copies of val/test data for faster evaluation\n",
    "# (i.e. set us up for vectorization)\n",
    "def rep(x):\n",
    "    rep_shape = torch.Size([x.size(0) * n_eval_samples]) + x.size()[1:]\n",
    "    repeat_dims = [1] * len(x.size())\n",
    "    repeat_dims[0] = n_eval_samples\n",
    "    return (\n",
    "        x.repeat(repeat_dims)\n",
    "        .reshape(n_eval_samples, -1)\n",
    "        .transpose(1, 0)\n",
    "        .reshape(rep_shape)\n",
    "    )\n",
    "\n",
    "# get the validation/test data ready for the dmm: pack into sequences, etc.\n",
    "val_seq_lengths = rep(val_seq_lengths)\n",
    "test_seq_lengths = rep(test_seq_lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "os.environ['PYTORCH_ENABLE_MPS_FALLBACK'] = '1'\n",
    "\n",
    "def reverse_sequences(mini_batch, seq_lengths):\n",
    "    reversed_mini_batch = torch.zeros_like(mini_batch)\n",
    "    for b in range(mini_batch.size(0)):\n",
    "        T = seq_lengths[b]\n",
    "        time_slice = torch.arange(T - 1, -1, -1, device=mini_batch.device)\n",
    "        reversed_sequence = torch.index_select(mini_batch[b, :, :], 0, time_slice)\n",
    "        reversed_mini_batch[b, 0:T, :] = reversed_sequence\n",
    "    return reversed_mini_batch\n",
    "\n",
    "def get_mini_batch_mask(mini_batch, seq_lengths):\n",
    "    mask = torch.zeros(mini_batch.shape[0:2])\n",
    "    for b in range(mini_batch.shape[0]):\n",
    "        mask[b, 0 : seq_lengths[b]] = torch.ones(seq_lengths[b])\n",
    "    return mask\n",
    "\n",
    "def get_mini_batch_mps(mini_batch_indices, sequences, seq_lengths, cuda=False, mps=True):\n",
    "\n",
    "    # get the sequence lengths of the mini-batch\n",
    "    seq_lengths = seq_lengths[mini_batch_indices]\n",
    "\n",
    "    # sort the sequence lengths\n",
    "    # indices should be either on cpu or on the same device as the indexed tensor (cpu)\n",
    "    _, sorted_seq_length_indices = torch.sort(seq_lengths)\n",
    "    sorted_seq_length_indices = sorted_seq_length_indices.flip(0)\n",
    "    sorted_seq_lengths = seq_lengths[sorted_seq_length_indices]\n",
    "    sorted_mini_batch_indices = mini_batch_indices[sorted_seq_length_indices]\n",
    "\n",
    "    # compute the length of the longest sequence in the mini-batch\n",
    "    T_max = torch.max(seq_lengths)\n",
    "    # this is the sorted mini-batch\n",
    "    mini_batch = sequences[sorted_mini_batch_indices, 0:T_max, :]\n",
    "    # this is the sorted mini-batch in reverse temporal order\n",
    "    mini_batch_reversed = reverse_sequences(mini_batch, sorted_seq_lengths)\n",
    "    # get mask for mini-batch\n",
    "    mini_batch_mask = get_mini_batch_mask(mini_batch, sorted_seq_lengths)\n",
    "\n",
    "    # cuda() here because need to cuda() before packing\n",
    "    if cuda:\n",
    "        mini_batch = mini_batch.cuda()\n",
    "        mini_batch_mask = mini_batch_mask.cuda()\n",
    "        mini_batch_reversed = mini_batch_reversed.cuda()\n",
    "\n",
    "    if mps:\n",
    "        mini_batch = mini_batch.to(torch.device('mps'))\n",
    "        mini_batch_mask = mini_batch_mask.to(torch.device('mps'))\n",
    "        mini_batch_reversed = mini_batch_reversed.to(torch.device('mps'))\n",
    "\n",
    "    # do sequence packing\n",
    "    mini_batch_reversed = nn.utils.rnn.pack_padded_sequence(\n",
    "        mini_batch_reversed, sorted_seq_lengths.to('cpu'), batch_first=True\n",
    "    )\n",
    "    mini_batch_reversed = mini_batch_reversed.to(torch.device('mps'))\n",
    "\n",
    "    return mini_batch, mini_batch_reversed, mini_batch_mask, sorted_seq_lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    val_batch,\n",
    "    val_batch_reversed,\n",
    "    val_batch_mask,\n",
    "    val_seq_lengths,\n",
    ") = get_mini_batch_mps(\n",
    "    torch.arange(n_eval_samples * val_data_sequences.shape[0]),\n",
    "    rep(val_data_sequences).to(torch.device('mps')),\n",
    "    val_seq_lengths.to(torch.device('mps')),\n",
    "    cuda=False, mps=True, \n",
    ")\n",
    "(\n",
    "    test_batch,\n",
    "    test_batch_reversed,\n",
    "    test_batch_mask,\n",
    "    test_seq_lengths,\n",
    ") = get_mini_batch_mps(\n",
    "    torch.arange(n_eval_samples * test_data_sequences.shape[0]),\n",
    "    rep(test_data_sequences).to(torch.device('mps')),\n",
    "    test_seq_lengths.to(torch.device('mps')),\n",
    "    cuda=False, mps=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define all the classes now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Emitter(nn.Module):\n",
    "    \"\"\"\n",
    "    Parameterizes the bernoulli observation likelihood `p(x_t | z_t)`\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, input_dim, z_dim, emission_dim):\n",
    "        super().__init__()\n",
    "        # initialize the three linear transformations used in the neural network\n",
    "        self.lin_z_to_hidden = nn.Linear(z_dim, emission_dim, device=torch.device('mps'))\n",
    "        self.lin_hidden_to_hidden = nn.Linear(emission_dim, emission_dim, device=torch.device('mps'))\n",
    "        self.lin_hidden_to_input = nn.Linear(emission_dim, input_dim, device=torch.device('mps'))\n",
    "        # initialize the two non-linearities used in the neural network\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, z_t):\n",
    "        \"\"\"\n",
    "        Given the latent z at a particular time step t we return the vector of\n",
    "        probabilities `ps` that parameterizes the bernoulli distribution `p(x_t|z_t)`\n",
    "        \"\"\"\n",
    "        h1 = self.relu(self.lin_z_to_hidden(z_t))\n",
    "        h2 = self.relu(self.lin_hidden_to_hidden(h1))\n",
    "        ps = torch.sigmoid(self.lin_hidden_to_input(h2))\n",
    "        return ps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GatedTransition(nn.Module):\n",
    "    \"\"\"\n",
    "    Parameterizes the gaussian latent transition probability `p(z_t | z_{t-1})`\n",
    "    See section 5 in the reference for comparison.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, z_dim, transition_dim):\n",
    "        super().__init__()\n",
    "        # initialize the six linear transformations used in the neural network\n",
    "        self.lin_gate_z_to_hidden = nn.Linear(z_dim, transition_dim, device=torch.device('mps'))\n",
    "        self.lin_gate_hidden_to_z = nn.Linear(transition_dim, z_dim, device=torch.device('mps'))\n",
    "        self.lin_proposed_mean_z_to_hidden = nn.Linear(z_dim, transition_dim, device=torch.device('mps'))\n",
    "        self.lin_proposed_mean_hidden_to_z = nn.Linear(transition_dim, z_dim, device=torch.device('mps'))\n",
    "        self.lin_sig = nn.Linear(z_dim, z_dim, device=torch.device('mps'))\n",
    "        self.lin_z_to_loc = nn.Linear(z_dim, z_dim, device=torch.device('mps'))\n",
    "        # modify the default initialization of lin_z_to_loc\n",
    "        # so that it's starts out as the identity function\n",
    "        self.lin_z_to_loc.weight.data = torch.eye(z_dim).to(torch.device('mps'))\n",
    "        self.lin_z_to_loc.bias.data = torch.zeros(z_dim).to(torch.device('mps'))\n",
    "        # initialize the three non-linearities used in the neural network\n",
    "        self.relu = nn.ReLU()\n",
    "        self.softplus = nn.Softplus()\n",
    "\n",
    "    def forward(self, z_t_1):\n",
    "        \"\"\"\n",
    "        Given the latent `z_{t-1}` corresponding to the time step t-1\n",
    "        we return the mean and scale vectors that parameterize the\n",
    "        (diagonal) gaussian distribution `p(z_t | z_{t-1})`\n",
    "        \"\"\"\n",
    "        # compute the gating function\n",
    "        _gate = self.relu(self.lin_gate_z_to_hidden(z_t_1))\n",
    "        gate = torch.sigmoid(self.lin_gate_hidden_to_z(_gate))\n",
    "        # compute the 'proposed mean'\n",
    "        _proposed_mean = self.relu(self.lin_proposed_mean_z_to_hidden(z_t_1))\n",
    "        proposed_mean = self.lin_proposed_mean_hidden_to_z(_proposed_mean)\n",
    "        # assemble the actual mean used to sample z_t, which mixes a linear transformation\n",
    "        # of z_{t-1} with the proposed mean modulated by the gating function\n",
    "        loc = (1 - gate) * self.lin_z_to_loc(z_t_1) + gate * proposed_mean\n",
    "        # compute the scale used to sample z_t, using the proposed mean from\n",
    "        # above as input the softplus ensures that scale is positive\n",
    "        scale = self.softplus(self.lin_sig(self.relu(proposed_mean)))\n",
    "        # return loc, scale which can be fed into Normal\n",
    "        return loc, scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Combiner(nn.Module):\n",
    "    \"\"\"\n",
    "    Parameterizes `q(z_t | z_{t-1}, x_{t:T})`, which is the basic building block\n",
    "    of the guide (i.e. the variational distribution). The dependence on `x_{t:T}` is\n",
    "    through the hidden state of the RNN (see the PyTorch module `rnn` below)\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, z_dim, rnn_dim):\n",
    "        super().__init__()\n",
    "        # initialize the three linear transformations used in the neural network\n",
    "        self.lin_z_to_hidden = nn.Linear(z_dim, rnn_dim, device=torch.device('mps'))\n",
    "        self.lin_hidden_to_loc = nn.Linear(rnn_dim, z_dim, device=torch.device('mps'))\n",
    "        self.lin_hidden_to_scale = nn.Linear(rnn_dim, z_dim, device=torch.device('mps'))\n",
    "        # initialize the two non-linearities used in the neural network\n",
    "        self.tanh = nn.Tanh()\n",
    "        self.softplus = nn.Softplus()\n",
    "\n",
    "    def forward(self, z_t_1, h_rnn):\n",
    "        \"\"\"\n",
    "        Given the latent z at at a particular time step t-1 as well as the hidden\n",
    "        state of the RNN `h(x_{t:T})` we return the mean and scale vectors that\n",
    "        parameterize the (diagonal) gaussian distribution `q(z_t | z_{t-1}, x_{t:T})`\n",
    "        \"\"\"\n",
    "        # combine the rnn hidden state with a transformed version of z_t_1\n",
    "        h_combined = 0.5 * (self.tanh(self.lin_z_to_hidden(z_t_1)) + h_rnn)\n",
    "        # use the combined hidden state to compute the mean used to sample z_t\n",
    "        loc = self.lin_hidden_to_loc(h_combined)\n",
    "        # use the combined hidden state to compute the scale used to sample z_t\n",
    "        scale = self.softplus(self.lin_hidden_to_scale(h_combined))\n",
    "        # return loc, scale which can be fed into Normal\n",
    "        return loc, scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DMM(nn.Module):\n",
    "    \"\"\"\n",
    "    This PyTorch Module encapsulates the model as well as the\n",
    "    variational distribution (the guide) for the Deep Markov Model\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        input_dim=88,\n",
    "        z_dim=100,\n",
    "        emission_dim=100,\n",
    "        transition_dim=200,\n",
    "        rnn_dim=600,\n",
    "        num_layers=1,\n",
    "        rnn_dropout_rate=0.1, #0.0,\n",
    "        num_iafs=0,\n",
    "        iaf_dim=100, #50,\n",
    "        use_cuda=False,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        # instantiate PyTorch modules used in the model and guide below\n",
    "        self.emitter = Emitter(input_dim, z_dim, emission_dim)\n",
    "        self.trans = GatedTransition(z_dim, transition_dim)\n",
    "        self.combiner = Combiner(z_dim, rnn_dim)\n",
    "        # dropout just takes effect on inner layers of rnn\n",
    "        rnn_dropout_rate = 0.0 if num_layers == 1 else rnn_dropout_rate\n",
    "        self.rnn = nn.RNN(\n",
    "            input_size=input_dim,\n",
    "            hidden_size=rnn_dim,\n",
    "            nonlinearity=\"relu\",\n",
    "            batch_first=True,\n",
    "            bidirectional=False,\n",
    "            num_layers=num_layers,\n",
    "            dropout=rnn_dropout_rate,\n",
    "            device=torch.device('mps'),\n",
    "        )\n",
    "\n",
    "        # if we're using normalizing flows, instantiate those too\n",
    "        self.iafs = [\n",
    "            affine_autoregressive(z_dim, hidden_dims=[iaf_dim]) for _ in range(num_iafs)\n",
    "        ]\n",
    "        self.iafs_modules = nn.ModuleList(self.iafs)\n",
    "\n",
    "        # define a (trainable) parameters z_0 and z_q_0 that help define the probability\n",
    "        # distributions p(z_1) and q(z_1)\n",
    "        # (since for t = 1 there are no previous latents to condition on)\n",
    "        self.z_0 = nn.Parameter(torch.zeros(z_dim).to(torch.device('mps')))\n",
    "        self.z_q_0 = nn.Parameter(torch.zeros(z_dim).to(torch.device('mps')))\n",
    "        # define a (trainable) parameter for the initial hidden state of the rnn\n",
    "        self.h_0 = nn.Parameter(torch.zeros(1, 1, rnn_dim).to(torch.device('mps')))\n",
    "\n",
    "        self.use_cuda = use_cuda\n",
    "        # if on gpu cuda-ize all PyTorch (sub)modules\n",
    "        if use_cuda:\n",
    "            self.cuda()\n",
    "\n",
    "    # the model p(x_{1:T} | z_{1:T}) p(z_{1:T})\n",
    "    def model(\n",
    "        self,\n",
    "        mini_batch,\n",
    "        mini_batch_reversed,\n",
    "        mini_batch_mask,\n",
    "        mini_batch_seq_lengths,\n",
    "        annealing_factor=1.0,\n",
    "    ):\n",
    "        # this is the number of time steps we need to process in the mini-batch\n",
    "        T_max = mini_batch.size(1)\n",
    "\n",
    "        # register all PyTorch (sub)modules with pyro\n",
    "        # this needs to happen in both the model and guide\n",
    "        pyro.module(\"dmm\", self)\n",
    "\n",
    "        # set z_prev = z_0 to setup the recursive conditioning in p(z_t | z_{t-1})\n",
    "        z_prev = self.z_0.expand(mini_batch.size(0), self.z_0.size(0))\n",
    "\n",
    "        # we enclose all the sample statements in the model in a plate.\n",
    "        # this marks that each datapoint is conditionally independent of the others\n",
    "        with pyro.plate(\"z_minibatch\", len(mini_batch), device=torch.device('mps')  ):\n",
    "            # sample the latents z and observed x's one time step at a time\n",
    "            # we wrap this loop in pyro.markov so that TraceEnum_ELBO can use multiple samples from the guide at each z\n",
    "            for t in pyro.markov(range(1, T_max + 1)):\n",
    "                # the next chunk of code samples z_t ~ p(z_t | z_{t-1})\n",
    "                # note that (both here and elsewhere) we use poutine.scale to take care\n",
    "                # of KL annealing. we use the mask() method to deal with raggedness\n",
    "                # in the observed data (i.e. different sequences in the mini-batch\n",
    "                # have different lengths)\n",
    "\n",
    "                # first compute the parameters of the diagonal gaussian distribution p(z_t | z_{t-1})\n",
    "                z_loc, z_scale = self.trans(z_prev)\n",
    "\n",
    "                # then sample z_t according to dist.Normal(z_loc, z_scale)\n",
    "                # note that we use the reshape method so that the univariate Normal distribution\n",
    "                # is treated as a multivariate Normal distribution with a diagonal covariance.\n",
    "                with poutine.scale(scale=annealing_factor):\n",
    "                    z_t = pyro.sample(\n",
    "                        \"z_%d\" % t,\n",
    "                        dist.Normal(z_loc.to(torch.device('mps')), z_scale.to(torch.device('mps')))\n",
    "                        .mask(mini_batch_mask[:, t - 1 : t])\n",
    "                        .to_event(1),\n",
    "                    )\n",
    "\n",
    "                # compute the probabilities that parameterize the bernoulli likelihood\n",
    "                emission_probs_t = self.emitter(z_t)\n",
    "                # the next statement instructs pyro to observe x_t according to the\n",
    "                # bernoulli distribution p(x_t|z_t)\n",
    "                pyro.sample(\n",
    "                    \"obs_x_%d\" % t,\n",
    "                    dist.Bernoulli(emission_probs_t.to(torch.device('mps')))\n",
    "                    .mask(mini_batch_mask[:, t - 1 : t])\n",
    "                    .to_event(1),\n",
    "                    obs=mini_batch[:, t - 1, :],\n",
    "                )\n",
    "                # the latent sampled at this time step will be conditioned upon\n",
    "                # in the next time step so keep track of it\n",
    "                z_prev = z_t\n",
    "\n",
    "    # the guide q(z_{1:T} | x_{1:T}) (i.e. the variational distribution)\n",
    "    def guide(\n",
    "        self,\n",
    "        mini_batch,\n",
    "        mini_batch_reversed,\n",
    "        mini_batch_mask,\n",
    "        mini_batch_seq_lengths,\n",
    "        annealing_factor=1.0,\n",
    "    ):\n",
    "        # this is the number of time steps we need to process in the mini-batch\n",
    "        T_max = mini_batch.size(1)\n",
    "        # register all PyTorch (sub)modules with pyro\n",
    "        pyro.module(\"dmm\", self)\n",
    "\n",
    "        # if on gpu we need the fully broadcast view of the rnn initial state\n",
    "        # to be in contiguous gpu memory\n",
    "        h_0_contig = self.h_0.expand(\n",
    "            1, mini_batch.size(0), self.rnn.hidden_size\n",
    "        ).contiguous()\n",
    "        # push the observed x's through the rnn;\n",
    "        # rnn_output contains the hidden state at each time step\n",
    "        rnn_output, _ = self.rnn(mini_batch_reversed, h_0_contig)\n",
    "        # reverse the time-ordering in the hidden state and un-pack it\n",
    "        rnn_output = poly.pad_and_reverse(rnn_output, mini_batch_seq_lengths)\n",
    "        # set z_prev = z_q_0 to setup the recursive conditioning in q(z_t |...)\n",
    "        z_prev = self.z_q_0.expand(mini_batch.size(0), self.z_q_0.size(0))\n",
    "\n",
    "        # we enclose all the sample statements in the guide in a plate.\n",
    "        # this marks that each datapoint is conditionally independent of the others.\n",
    "        with pyro.plate(\"z_minibatch\", len(mini_batch), device=torch.device('mps') ):\n",
    "            # sample the latents z one time step at a time\n",
    "            # we wrap this loop in pyro.markov so that TraceEnum_ELBO can use multiple samples from the guide at each z\n",
    "            for t in pyro.markov(range(1, T_max + 1)):\n",
    "                # the next two lines assemble the distribution q(z_t | z_{t-1}, x_{t:T})\n",
    "\n",
    "                z_loc, z_scale = self.combiner(z_prev, rnn_output[:, t - 1, :])\n",
    "\n",
    "\n",
    "                # if we are using normalizing flows, we apply the sequence of transformations\n",
    "                # parameterized by self.iafs to the base distribution defined in the previous line\n",
    "                # to yield a transformed distribution that we use for q(z_t|...)\n",
    "                if len(self.iafs) > 0:\n",
    "                    z_dist = TransformedDistribution(\n",
    "                        dist.Normal(z_loc.to(torch.device('mps')), z_scale.to(torch.device('mps'))), self.iafs\n",
    "                    )\n",
    "                    assert z_dist.event_shape == (self.z_q_0.size(0),)\n",
    "                    assert z_dist.batch_shape[-1:] == (len(mini_batch),)\n",
    "                else:\n",
    "                    z_dist = dist.Normal(z_loc, z_scale)\n",
    "                    assert z_dist.event_shape == ()\n",
    "                    assert z_dist.batch_shape[-2:] == (\n",
    "                        len(mini_batch),\n",
    "                        self.z_q_0.size(0),\n",
    "                    )\n",
    "\n",
    "                # sample z_t from the distribution z_dist\n",
    "                with pyro.poutine.scale(scale=annealing_factor):\n",
    "                    if len(self.iafs) > 0:\n",
    "                        # in output of normalizing flow, all dimensions are correlated (event shape is not empty)\n",
    "                        z_t = pyro.sample(\n",
    "                            \"z_%d\" % t, z_dist.mask(mini_batch_mask[:, t - 1])\n",
    "                        )\n",
    "                    else:\n",
    "                        # when no normalizing flow used, \".to_event(1)\" indicates latent dimensions are independent\n",
    "                        z_t = pyro.sample(\n",
    "                            \"z_%d\" % t,\n",
    "                            z_dist.mask(mini_batch_mask[:, t - 1 : t]).to_event(1),\n",
    "                        )\n",
    "                # the latent sampled at this time step will be conditioned upon in the next time step\n",
    "                # so keep track of it\n",
    "                z_prev = z_t\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Instantiate the dmm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "dmm = DMM(\n",
    "    rnn_dropout_rate=rdr,\n",
    "    num_iafs=iafs,\n",
    "    iaf_dim=id,\n",
    "    use_cuda=cuda,\n",
    ").to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "adam_params = {\n",
    "    \"lr\": lr,\n",
    "    \"betas\": (b1, b2),\n",
    "    \"clip_norm\": cn,\n",
    "    \"lrd\": lrd,\n",
    "    \"weight_decay\": wd,\n",
    "}\n",
    "adam = ClippedAdam(adam_params)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup inference algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "if tmc:\n",
    "    if jit:\n",
    "        raise NotImplementedError(\"no JIT support yet for TMC\")\n",
    "    tmc_loss = TraceTMC_ELBO()\n",
    "    dmm_guide = config_enumerate(\n",
    "        dmm.guide,\n",
    "        default=\"parallel\",\n",
    "        num_samples=tmc_num_samples,\n",
    "        expand=False,\n",
    "    )\n",
    "    svi = SVI(dmm.model, dmm_guide, adam, loss=tmc_loss)\n",
    "elif tmcelbo:\n",
    "    if jit:\n",
    "        raise NotImplementedError(\"no JIT support yet for TMC ELBO\")\n",
    "    elbo = TraceEnum_ELBO()\n",
    "    dmm_guide = config_enumerate(\n",
    "        dmm.guide,\n",
    "        default=\"parallel\",\n",
    "        num_samples=tmc_num_samples,\n",
    "        expand=False,\n",
    "    )\n",
    "    svi = SVI(dmm.model, dmm_guide, adam, loss=elbo)\n",
    "else:\n",
    "    elbo = JitTrace_ELBO() if jit else Trace_ELBO()\n",
    "    svi = SVI(dmm.model, dmm.guide, adam, loss=elbo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Now we're going to define some functions we need to form the main training loop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saves the model and optimizer states to disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_checkpoint():\n",
    "    logging.info(\"saving model to %s...\" % smod)\n",
    "    torch.save(dmm.state_dict(), smod)\n",
    "    logging.info(\"saving optimizer states to %s...\" % sopt)\n",
    "    adam.save(sopt)\n",
    "    logging.info(\"done saving model and optimizer checkpoints to disk.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loads the model and optimizer states from disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_checkpoint():\n",
    "    assert exists(lopt) and exists(\n",
    "        lmod\n",
    "    ), \"--load-model and/or --load-opt misspecified\"\n",
    "    logging.info(\"loading model from %s...\" % lmod)\n",
    "    dmm.load_state_dict(torch.load(lmod, weights_only=False))\n",
    "    logging.info(\"loading optimizer states from %s...\" % lopt)\n",
    "    adam.load(lopt)\n",
    "    logging.info(\"done loading model and optimizer states.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare a mini-batch and take a gradient step to minimize -elbo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# JD - need to modify this to use MPS\n",
    "import os\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "os.environ['PYTORCH_ENABLE_MPS_FALLBACK'] = '1'\n",
    "\n",
    "def process_minibatch(epoch, which_mini_batch, shuffled_indices):\n",
    "    if ae > 0 and epoch < ae:\n",
    "        # compute the KL annealing factor approriate for the current mini-batch in the current epoch\n",
    "        min_af = maf\n",
    "        annealing_factor = min_af + (1.0 - min_af) * (\n",
    "            float(which_mini_batch + epoch * N_mini_batches + 1)\n",
    "            / float(ae * N_mini_batches)\n",
    "        )\n",
    "    else:\n",
    "        # by default the KL annealing factor is unity\n",
    "        annealing_factor = 1.0\n",
    "\n",
    "    # compute which sequences in the training set we should grab\n",
    "    mini_batch_start = which_mini_batch * mbs\n",
    "    mini_batch_end = np.min(\n",
    "        [(which_mini_batch + 1) * mbs, N_train_data]\n",
    "    )\n",
    "    mini_batch_indices = shuffled_indices[mini_batch_start:mini_batch_end]\n",
    "    # grab a fully prepped mini-batch using the helper function in the data loader\n",
    "    (\n",
    "        mini_batch,\n",
    "        mini_batch_reversed,\n",
    "        mini_batch_mask,\n",
    "        mini_batch_seq_lengths,\n",
    "    ) = get_mini_batch_mps(\n",
    "        mini_batch_indices,\n",
    "        training_data_sequences.to(torch.device('mps')),\n",
    "        training_seq_lengths.to(torch.device('mps')),\n",
    "        cuda=False, mps=True,\n",
    "    )\n",
    "\n",
    "    # do an actual gradient step\n",
    "    loss = svi.step(\n",
    "        mini_batch,\n",
    "        mini_batch_reversed,\n",
    "        mini_batch_mask,\n",
    "        mini_batch_seq_lengths,\n",
    "        annealing_factor,\n",
    "    )\n",
    "    # keep track of the training loss\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helper function for doing evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_evaluation():\n",
    "    # put the RNN into evaluation mode (i.e. turn off drop-out if applicable)\n",
    "    dmm.rnn.eval()\n",
    "\n",
    "    # compute the validation and test loss n_samples many times\n",
    "    val_nll = svi.evaluate_loss(\n",
    "        val_batch, val_batch_reversed, val_batch_mask, val_seq_lengths\n",
    "    ) / float(torch.sum(val_seq_lengths))\n",
    "    test_nll = svi.evaluate_loss(\n",
    "        test_batch, test_batch_reversed, test_batch_mask, test_seq_lengths\n",
    "    ) / float(torch.sum(test_seq_lengths))\n",
    "\n",
    "    # put the RNN back into training mode (i.e. turn on drop-out if applicable)\n",
    "    dmm.rnn.train()\n",
    "    return val_nll, test_nll\n",
    "\n",
    "# if checkpoint files provided, load model and optimizer states from disk before we start training\n",
    "if lopt != \"\" and lmod != \"\":\n",
    "    load_checkpoint()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[training epoch 0000]  62.9117 \t\t\t\t(dt = 23.994 sec)\n",
      "[training epoch 0001]  57.9943 \t\t\t\t(dt = 20.723 sec)\n",
      "[training epoch 0002]  41.6934 \t\t\t\t(dt = 21.538 sec)\n",
      "[training epoch 0003]  23.1886 \t\t\t\t(dt = 20.541 sec)\n",
      "[training epoch 0004]  17.2338 \t\t\t\t(dt = 21.395 sec)\n",
      "[training epoch 0005]  14.7713 \t\t\t\t(dt = 21.725 sec)\n",
      "[training epoch 0006]  13.3703 \t\t\t\t(dt = 22.322 sec)\n",
      "[training epoch 0007]  12.4769 \t\t\t\t(dt = 22.209 sec)\n",
      "[training epoch 0008]  12.0307 \t\t\t\t(dt = 20.665 sec)\n",
      "[training epoch 0009]  11.8544 \t\t\t\t(dt = 20.997 sec)\n"
     ]
    }
   ],
   "source": [
    "times = [time.time()]\n",
    "for epoch in range(n):\n",
    "    # if specified, save model and optimizer states to disk every checkpoint_freq epochs\n",
    "    if cf > 0 and epoch > 0 and epoch % cf == 0:\n",
    "        save_checkpoint()\n",
    "\n",
    "    # accumulator for our estimate of the negative log likelihood (or rather -elbo) for this epoch\n",
    "    epoch_nll = 0.0\n",
    "    # prepare mini-batch subsampling indices for this epoch\n",
    "    shuffled_indices = torch.randperm(N_train_data)\n",
    "\n",
    "    # process each mini-batch; this is where we take gradddient steps\n",
    "    for which_mini_batch in range(N_mini_batches):\n",
    "        # print(which_mini_batch)\n",
    "        epoch_nll += process_minibatch(epoch, which_mini_batch, shuffled_indices)\n",
    "\n",
    "    # report training diagnostics\n",
    "    times.append(time.time())\n",
    "    epoch_time = times[-1] - times[-2]\n",
    "    logging.info(\n",
    "        \"[training epoch %04d]  %.4f \\t\\t\\t\\t(dt = %.3f sec)\"\n",
    "        % (epoch, epoch_nll / N_train_time_slices, epoch_time)\n",
    "    )\n",
    "\n",
    "    # do evaluation on test and validation data and report results\n",
    "    if val_test_frequency > 0 and epoch > 0 and epoch % val_test_frequency == 0:\n",
    "        val_nll, test_nll = do_evaluation()\n",
    "        logging.info(\n",
    "            \"[val/test epoch %04d]  %.4f  %.4f\" % (epoch, val_nll, test_nll)\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion: It looks like the GPU using Pyro is not effective at all. Using CPU gives roughly 3.5 seconds per epoch whereas using GPU gives ~22 seconds per epoch. I don't know perhaps Pyro is more suitable for CUDA and not MPS. I will try to see if NumPyro is better because it has the same set of nice examples of Deep Markov Model, and also uses JAX."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "opensendaibench",
   "language": "python",
   "name": "opensendaibench"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
